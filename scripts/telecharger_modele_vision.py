#!/usr/bin/env python3
"""Script pour tÃ©lÃ©charger et prÃ©-cacher les modÃ¨les de vision (BLIP + traduction).

Ce script tÃ©lÃ©charge:
- BLIP pour la description d'images (Salesforce/blip-image-captioning-base)
- MarianMT pour la traduction EN->FR (Helsinki-NLP/opus-mt-en-fr)

Ces modÃ¨les sont utilisÃ©s pour gÃ©nÃ©rer des descriptions textuelles des images
avant de les encoder avec le modÃ¨le d'embedding.
"""

import io
import sys
from pathlib import Path

# Forcer UTF-8 pour la sortie console (nÃ©cessaire pour les emojis sur Windows)
if sys.stdout.encoding != 'utf-8':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
if sys.stderr.encoding != 'utf-8':
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

# Ajouter le rÃ©pertoire racine au path pour les imports
racine_projet = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(racine_projet))

from transformers import (
    BlipForConditionalGeneration,
    BlipProcessor,
    MarianMTModel,
    MarianTokenizer,
)


def telecharger_modeles_vision():
    """TÃ©lÃ©charge et met en cache les modÃ¨les de vision."""
    print("=" * 70)
    print("=== TÃ©lÃ©chargement des modÃ¨les de vision ===")
    print("=" * 70)
    
    # ========== BLIP ==========
    print("\nğŸ–¼ï¸  Ã‰tape 1/2: TÃ©lÃ©chargement du modÃ¨le BLIP...")
    print("   ModÃ¨le: Salesforce/blip-image-captioning-base")
    print("   Taille: ~990MB")
    print("   Usage: GÃ©nÃ©ration de descriptions d'images en anglais")
    
    try:
        print("\n   TÃ©lÃ©chargement en cours...")
        processor_blip = BlipProcessor.from_pretrained(
            "Salesforce/blip-image-captioning-base"
        )
        modele_blip = BlipForConditionalGeneration.from_pretrained(
            "Salesforce/blip-image-captioning-base"
        )
        
        print("   âœ… BLIP tÃ©lÃ©chargÃ© avec succÃ¨s!")
        print(f"   Cache: {modele_blip.config._name_or_path}")
        
    except Exception as e:
        print(f"   âŒ Erreur lors du tÃ©lÃ©chargement de BLIP: {e}")
        return False
    
    # ========== MarianMT EN->FR ==========
    print("\nğŸŒ Ã‰tape 2/2: TÃ©lÃ©chargement du modÃ¨le de traduction EN->FR...")
    print("   ModÃ¨le: Helsinki-NLP/opus-mt-en-fr")
    print("   Taille: ~300MB")
    print("   Usage: Traduction anglais->franÃ§ais des descriptions")
    
    try:
        print("\n   TÃ©lÃ©chargement en cours...")
        tokenizer_trad = MarianTokenizer.from_pretrained(
            "Helsinki-NLP/opus-mt-en-fr"
        )
        modele_trad = MarianMTModel.from_pretrained(
            "Helsinki-NLP/opus-mt-en-fr"
        )
        
        print("   âœ… Traducteur tÃ©lÃ©chargÃ© avec succÃ¨s!")
        print(f"   Cache: {modele_trad.config._name_or_path}")
        
    except Exception as e:
        print(f"   âŒ Erreur lors du tÃ©lÃ©chargement du traducteur: {e}")
        return False
    
    # ========== Test rapide ==========
    print("\nğŸ§ª Test rapide des modÃ¨les...")
    
    try:
        from PIL import Image
        import numpy as np
        
        # CrÃ©er une image de test (100x100 pixels, bleu)
        image_test = Image.fromarray(
            np.full((100, 100, 3), [0, 0, 255], dtype=np.uint8)
        )
        
        # Test BLIP
        print("   Test BLIP...")
        inputs = processor_blip(image_test, return_tensors="pt")
        outputs = modele_blip.generate(**inputs, max_length=50)
        caption_en = processor_blip.decode(outputs[0], skip_special_tokens=True)
        print(f"   Description gÃ©nÃ©rÃ©e: '{caption_en}'")
        
        # Test traduction
        print("   Test traducteur...")
        inputs_trad = tokenizer_trad(caption_en, return_tensors="pt")
        translated = modele_trad.generate(**inputs_trad)
        caption_fr = tokenizer_trad.decode(translated[0], skip_special_tokens=True)
        print(f"   Traduction: '{caption_fr}'")
        
        print("\n   âœ… Tests rÃ©ussis!")
        
    except Exception as e:
        print(f"   âš ï¸  Erreur lors des tests: {e}")
        print("   Les modÃ¨les ont Ã©tÃ© tÃ©lÃ©chargÃ©s mais le test a Ã©chouÃ©.")
        print("   VÃ©rifiez les dÃ©pendances (PIL, torch, transformers)")
    
    return True


if __name__ == "__main__":
    print("\nğŸ“¦ TÃ©lÃ©chargement des modÃ¨les de vision pour OPSEMIA")
    print("âš ï¸  Ce tÃ©lÃ©chargement peut prendre plusieurs minutes (~1.3GB total)")
    print("Assurez-vous d'avoir une connexion internet stable.\n")
    
    succes = telecharger_modeles_vision()
    
    if succes:
        print("\n" + "=" * 70)
        print("ğŸ‰ Les modÃ¨les de vision sont maintenant prÃªts Ã  Ãªtre utilisÃ©s!")
        print("=" * 70)
        print("\nğŸ“ Prochaines Ã©tapes:")
        print("   1. PrÃ©parez votre CSV d'images (images.csv)")
        print("   2. Lancez l'application: python src/backend/app.py")
        print("   3. Indexez vos images via l'interface web (Configuration)")
        print()
    else:
        print("\n" + "=" * 70)
        print("ğŸ’¥ Ã‰chec du tÃ©lÃ©chargement")
        print("=" * 70)
        print("\nğŸ”§ VÃ©rifications:")
        print("   â€¢ Connexion internet active")
        print("   â€¢ Espace disque suffisant (~1.5GB)")
        print("   â€¢ DÃ©pendances installÃ©es: pip install -r requirements.txt")
        print()
        sys.exit(1)


