"""Pipeline d'indexation d'images : CSV â†’ Description â†’ Encodage â†’ ChromaDB.

Ce module gÃ¨re l'indexation complÃ¨te des images avec gÃ©nÃ©ration de descriptions
textuelles et embeddings vectoriels.
"""

from __future__ import annotations

import io
import sys
import time
from pathlib import Path
from typing import Any, Dict, List, Optional

import numpy as np
from PIL import Image

# Forcer UTF-8 pour la sortie console
if sys.stdout.encoding != 'utf-8':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
if sys.stderr.encoding != 'utf-8':
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

# Ajouter le rÃ©pertoire racine au path pour les imports
racine_projet = Path(__file__).resolve().parents[3]
sys.path.insert(0, str(racine_projet))

from config.settings import Parametres
from src.backend.database.vector_db import BaseVectorielle
from src.backend.models.image_encoder import creer_encodeur_image
from src.backend.models.model_manager import obtenir_encodeur_texte
from src.backend.parsers.image_extractor import parser_images_depuis_csv


def indexer_csv_images(
    chemin_csv: str | Path,
    parametres: Parametres,
    nom_cas: Optional[str] = None,
    reinitialiser: bool = False,
    progress_callback: Optional[callable] = None,
    log_verbose: bool = False,
) -> Dict[str, Any]:
    """Pipeline complet d'indexation d'un CSV d'images dans ChromaDB.
    
    Ã‰tapes:
    1. Parsing du CSV d'images
    2. GÃ©nÃ©ration des descriptions textuelles (BLIP + traduction)
    3. Encodage vectoriel des descriptions
    4. Stockage dans ChromaDB
    
    Args:
        chemin_csv: Chemin vers le fichier CSV d'images
        parametres: ParamÃ¨tres de configuration
        nom_cas: Nom du cas pour les collections (ex: "cas4"). Si None, utilise le nom par dÃ©faut
        reinitialiser: Si True, supprime la collection existante avant d'indexer
        progress_callback: Fonction de callback pour la progression (etape, %, message)
        log_verbose: Si True, affiche chaque image encodÃ©e (verbeux pour gros fichiers)
        
    Returns:
        Statistiques d'indexation (nombre d'images, durÃ©e, etc.)
    """
    debut_total = time.time()
    stats = {
        "fichier_csv": str(chemin_csv),
        "nom_cas": nom_cas,
        "images_indexees": 0,
        "images_manquantes": 0,
        "duree_parsing_sec": 0,
        "duree_description_sec": 0,
        "duree_encodage_sec": 0,
        "duree_stockage_sec": 0,
        "duree_totale_sec": 0,
    }
    
    # Nom de la collection (avec suffixe de cas si spÃ©cifiÃ©)
    suffixe = f"_{nom_cas}" if nom_cas else ""
    nom_collection_images = parametres.NOM_COLLECTION_IMAGES + suffixe
    
    print(f"ðŸ–¼ï¸  DÃ©marrage de l'indexation d'images: {chemin_csv}")
    print(f"   Collection: {nom_collection_images}")
    
    # Helper pour envoyer la progression
    def _emit_progress(etape: str, pct: float, msg: str):
        if progress_callback:
            progress_callback(etape, pct, msg)
    
    _emit_progress("initialisation", 0, "DÃ©marrage de l'indexation d'images...")
    
    # ========== 1. PARSING ==========
    print("\nðŸ“„ Phase 1/4: Parsing du CSV d'images...")
    _emit_progress("parsing", 5, "Lecture du fichier CSV d'images...")
    debut_phase = time.time()
    
    # DÃ©terminer le dossier des images
    chemin_csv_path = Path(chemin_csv)
    dossier_images = chemin_csv_path.parent
    
    images = parser_images_depuis_csv(chemin_csv_path, dossier_images)
    stats["duree_parsing_sec"] = time.time() - debut_phase
    
    # Filtrer les images existantes
    images_valides = [img for img in images if img["existe"]]
    stats["images_manquantes"] = len(images) - len(images_valides)
    
    print(f"   âœ“ {len(images)} images parsÃ©es, {len(images_valides)} valides ({stats['duree_parsing_sec']:.2f}s)")
    if stats["images_manquantes"] > 0:
        print(f"   âš ï¸  {stats['images_manquantes']} image(s) manquante(s) (ignorÃ©es)")
    
    _emit_progress("parsing", 10, f"{len(images_valides)} images valides trouvÃ©es")
    
    if len(images_valides) == 0:
        print("\nâŒ Aucune image valide Ã  indexer!")
        return stats
    
    # ========== 2. CHARGEMENT DES MODÃˆLES ==========
    print("\nðŸ§  Phase 2/4: Chargement des modÃ¨les...")
    _emit_progress("chargement_modeles", 12, "Chargement des modÃ¨les de vision et d'encodage...")
    debut_phase = time.time()
    
    # Charger l'encodeur de texte (partagÃ© avec les messages)
    encodeur_texte = obtenir_encodeur_texte()
    
    # CrÃ©er l'encodeur d'images
    encodeur_image = creer_encodeur_image(encodeur_texte, parametres)
    dimension_embedding = encodeur_image.dimension_embedding
    
    duree_chargement = time.time() - debut_phase
    print(f"   âœ“ ModÃ¨les chargÃ©s (dim={dimension_embedding}) ({duree_chargement:.2f}s)")
    _emit_progress("chargement_modeles", 20, "ModÃ¨les chargÃ©s")
    
    # ========== 3. DESCRIPTION ET ENCODAGE ==========
    print("\nðŸ–¼ï¸  Phase 3/4: Description et encodage des images...")
    _emit_progress("encodage", 22, f"Traitement de {len(images_valides)} images...")
    debut_phase = time.time()
    
    embeddings_liste = []
    descriptions_liste = []
    images_traitees = []
    
    total_images = len(images_valides)
    temps_par_image = []
    
    for i, image_info in enumerate(images_valides):
        debut_image = time.time()
        
        try:
            # Charger l'image
            chemin_absolu = Path(image_info["chemin_absolu"])
            image_pil = Image.open(chemin_absolu).convert("RGB")
            
            # Encoder l'image (description + embedding)
            embedding, description = encodeur_image.encoder_image(image_pil)
            
            embeddings_liste.append(embedding)
            descriptions_liste.append(description)
            images_traitees.append(image_info)
            
            duree_image = time.time() - debut_image
            temps_par_image.append(duree_image)
            
            # Progression
            pct = 22 + (i + 1) / total_images * 58  # 22-80%
            
            # Log du traitement avec la description TOUJOURS affichÃ©e
            apercu_nom = (image_info["nom_image"][:40] + "...") if len(image_info["nom_image"]) > 40 else image_info["nom_image"]
            print(f"   â”œâ”€ [{i+1}/{total_images}] {apercu_nom} ({duree_image:.2f}s)")
            
            # TOUJOURS afficher la description gÃ©nÃ©rÃ©e (aprÃ¨s traduction EN->FR)
            apercu_desc = (description[:100] + "...") if len(description) > 100 else description
            print(f"      â””â”€ ðŸ‡«ðŸ‡· Description: {apercu_desc}")
            
            # Ã‰mettre la progression
            _emit_progress(
                "encodage",
                pct,
                f"Image {i+1}/{total_images}: {apercu_nom}"
            )
            
        except Exception as e:
            print(f"\n   âš ï¸  Erreur lors du traitement de l'image {image_info['nom_image']}: {e}")
            continue
    
    stats["duree_description_sec"] = time.time() - debut_phase
    stats["duree_encodage_sec"] = stats["duree_description_sec"]  # CombinÃ©
    
    # Statistiques de traitement
    if temps_par_image:
        temps_moyen = np.mean(temps_par_image)
        temps_min = np.min(temps_par_image)
        temps_max = np.max(temps_par_image)
        
        stats["temps_moyen_par_image"] = temps_moyen
        stats["temps_min_par_image"] = temps_min
        stats["temps_max_par_image"] = temps_max
        stats["debit_images_par_sec"] = len(temps_par_image) / stats["duree_encodage_sec"]
        
        print(f"\n   âœ“ {len(embeddings_liste)} images traitÃ©es ({stats['duree_encodage_sec']:.2f}s)")
        print(f"   ðŸ“Š Stats traitement:")
        print(f"      â€¢ Temps moyen/image: {temps_moyen:.2f}s")
        print(f"      â€¢ Plus rapide: {temps_min:.2f}s | Plus lent: {temps_max:.2f}s")
        print(f"      â€¢ DÃ©bit: {stats['debit_images_par_sec']:.2f} img/s")
    
    _emit_progress("encodage", 80, f"{len(embeddings_liste)} images encodÃ©es")
    
    if len(embeddings_liste) == 0:
        print("\nâŒ Aucune image n'a pu Ãªtre traitÃ©e!")
        return stats
    
    # ========== 4. STOCKAGE CHROMADB ==========
    print("\nðŸ’¾ Phase 4/4: Stockage dans ChromaDB...")
    _emit_progress("stockage", 82, "Connexion Ã  ChromaDB...")
    debut_phase = time.time()
    
    db = BaseVectorielle(chemin_persistance=parametres.CHEMIN_BASE_CHROMA)
    
    # RÃ©initialiser si demandÃ©
    if reinitialiser:
        print("   âš ï¸  RÃ©initialisation de la collection existante...")
        _emit_progress("stockage", 84, "Suppression des anciennes donnÃ©es...")
        db.supprimer_collection(nom_collection_images)
    
    # Stocker les images
    print("   â†’ Stockage des images...")
    _emit_progress("stockage", 86, f"Stockage de {len(images_traitees)} images...")
    
    # PrÃ©parer les IDs et mÃ©tadonnÃ©es
    ids_images = [
        img.get("id") or f"img_{i}" 
        for i, img in enumerate(images_traitees)
    ]
    
    # Nettoyer les descriptions et extraire les mÃ©tadonnÃ©es
    metadonnees_images = []
    descriptions_nettoyees = []
    for img, desc in zip(images_traitees, descriptions_liste):
        meta = _extraire_metadonnees_image(img, desc)
        metadonnees_images.append(meta)
        descriptions_nettoyees.append(meta["description"])  # Description nettoyÃ©e
    
    # Convertir les embeddings en liste
    embeddings_array = np.array(embeddings_liste)
    
    db.ajouter_messages(
        nom_collection=nom_collection_images,
        ids=ids_images,
        embeddings=embeddings_array.tolist(),
        metadonnees=metadonnees_images,
        documents=descriptions_nettoyees,  # Utiliser les descriptions nettoyÃ©es
    )
    
    stats["images_indexees"] = len(ids_images)
    stats["duree_stockage_sec"] = time.time() - debut_phase
    
    print(f"   âœ“ Stockage terminÃ© ({stats['duree_stockage_sec']:.2f}s)")
    _emit_progress("stockage", 100, "Indexation d'images terminÃ©e avec succÃ¨s!")
    
    # ========== RÃ‰SUMÃ‰ ==========
    stats["duree_totale_sec"] = time.time() - debut_total
    
    print("\n" + "="*70)
    print("âœ… INDEXATION D'IMAGES TERMINÃ‰E")
    print("="*70)
    print(f"ðŸ“Š RÃ©sultats:")
    print(f"   â€¢ Images parsÃ©es      : {len(images)}")
    print(f"   â€¢ Images indexÃ©es     : {stats['images_indexees']}")
    print(f"   â€¢ Images manquantes   : {stats['images_manquantes']}")
    print(f"\nâ±ï¸  DurÃ©es par phase:")
    print(f"   â€¢ Parsing             : {stats['duree_parsing_sec']:.2f}s ({stats['duree_parsing_sec']/stats['duree_totale_sec']*100:.1f}%)")
    print(f"   â€¢ Description+Encodage: {stats['duree_encodage_sec']:.2f}s ({stats['duree_encodage_sec']/stats['duree_totale_sec']*100:.1f}%)")
    print(f"   â€¢ Stockage            : {stats['duree_stockage_sec']:.2f}s ({stats['duree_stockage_sec']/stats['duree_totale_sec']*100:.1f}%)")
    print(f"   â€¢ TOTAL               : {stats['duree_totale_sec']:.2f}s")
    
    if "debit_images_par_sec" in stats:
        print(f"\nðŸ“ˆ Performance:")
        print(f"   â€¢ Temps moyen/image: {stats['temps_moyen_par_image']:.2f}s")
        print(f"   â€¢ Plus rapide: {stats['temps_min_par_image']:.2f}s | Plus lent: {stats['temps_max_par_image']:.2f}s")
        print(f"   â€¢ DÃ©bit: {stats['debit_images_par_sec']:.2f} images/s")
    
    print(f"\nðŸ’¾ Collection crÃ©Ã©e: {nom_collection_images}")
    print(f"ðŸ“ Base ChromaDB: {parametres.CHEMIN_BASE_CHROMA}")
    print("="*70)
    
    return stats


def _extraire_metadonnees_image(
    image_info: Dict[str, Any],
    description: str,
) -> Dict[str, Any]:
    """Extrait les mÃ©tadonnÃ©es pertinentes d'une image pour ChromaDB.
    
    Args:
        image_info: Informations de l'image (depuis le parser)
        description: Description textuelle gÃ©nÃ©rÃ©e
        
    Returns:
        MÃ©tadonnÃ©es JSON-serializable
    """
    # Nettoyer la description des rÃ©pÃ©titions de mots consÃ©cutifs
    description_nettoyee = _nettoyer_repetitions(description)
    
    return {
        "nom_image": image_info.get("nom_image", ""),
        "chemin": image_info.get("chemin", ""),
        "timestamp": image_info.get("timestamp", ""),
        "date_prise": image_info.get("date_prise", ""),
        "heure_prise": image_info.get("heure_prise", ""),
        "gps_lat": image_info.get("gps_lat") or 0.0,
        "gps_lon": image_info.get("gps_lon") or 0.0,
        "description": description_nettoyee,
        "type": "image",  # Flag pour distinguer des messages
        "is_noise": False,  # Les images ne sont jamais du bruit (compatibilitÃ© filtre)
    }


def _nettoyer_repetitions(texte: str) -> str:
    """Supprime les mots qui se rÃ©pÃ¨tent consÃ©cutivement dans un texte.
    
    GÃ¨re les rÃ©pÃ©titions avec espaces, virgules, et ponctuation.
    
    Exemple: 
        "un chat chat chat noir" -> "un chat noir"
        "miami, miami, miami" -> "miami"
        "salon, salon salon" -> "salon"
    
    Args:
        texte: Texte Ã  nettoyer
        
    Returns:
        Texte sans rÃ©pÃ©titions consÃ©cutives
    """
    import re
    
    # Pattern amÃ©liorÃ© pour gÃ©rer les rÃ©pÃ©titions avec virgules OU espaces
    # Capture: (mot) (sÃ©parateur) (mot rÃ©pÃ©tÃ©) (sÃ©parateur)...
    # Remplace par: (mot) (un seul sÃ©parateur appropriÃ©)
    
    # D'abord gÃ©rer les rÃ©pÃ©titions avec virgules: "miami, miami, miami" -> "miami"
    texte_nettoye = re.sub(
        r'\b(\w+)(?:\s*,\s*\1)+\b',  # mot, mot, mot...
        r'\1',
        texte,
        flags=re.IGNORECASE
    )
    
    # Ensuite gÃ©rer les rÃ©pÃ©titions avec espaces: "chat chat chat" -> "chat"
    texte_nettoye = re.sub(
        r'\b(\w+)(?:\s+\1)+\b',  # mot mot mot...
        r'\1',
        texte_nettoye,
        flags=re.IGNORECASE
    )
    
    # Nettoyer les virgules orphelines (ex: ", , ," -> ",")
    texte_nettoye = re.sub(r',(\s*,)+', ',', texte_nettoye)
    
    # Nettoyer les espaces multiples
    texte_nettoye = re.sub(r'\s+', ' ', texte_nettoye)
    
    # Nettoyer virgule en fin de phrase
    texte_nettoye = re.sub(r',\s*$', '', texte_nettoye)
    
    return texte_nettoye.strip()


